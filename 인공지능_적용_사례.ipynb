{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인공지능 적용 사례.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYZ5PrC3Ye30DuIEFtiAGy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kim-sangha/AI-school/blob/master/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5_%EC%A0%81%EC%9A%A9_%EC%82%AC%EB%A1%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6PF0pGA_5TX",
        "colab_type": "text"
      },
      "source": [
        "#인공지능 적용 사례"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRqisaCGyfEn",
        "colab_type": "text"
      },
      "source": [
        "## 1. 언어 분야\n",
        "\n",
        "\n",
        "* 보편적으로 사용되고 있는 AI 기술은 자동번역 및 통역 등을 처리해주는 '자연언어 처리 기술'이다. 과거에는 '통계 기반 기계번역(SMT)'방식으로, 단어나 문맥을 제대로 파악하지 못해 오역되거나 해석할 수 없어, 자연스럽지 않은 번역의 티가 많이 났었다. 하지만, 지금은 '인공 신경망(NMT)'기반으로 기술이 발달하면서 실생활에서 활용될만한 수준의 통 번역본은 물론 더욱더 인간의 언어에 가까운 말투로 문장을 번역해 주고 있다.   \n",
        "\n",
        "\n",
        "* 언어 분야에 인공지능이 적용된 사례로는 타임케틀 사의 **'WT2'**이 있다.\n",
        "타임케틀의 **'WT2'**는 동시통역이 가능한 무선 이어폰으로 전 세계 36개 언어를 지원한다. 번역 과정이 전용 앱과 연동되기 때문에 통역이 필요한 순간에 버튼을 누를 필요가 없다. 또한 이어폰 장착 후 자신의 언어로 말하면 상대방에게 번역된 언어가 음성으로 전달된다.   \n",
        "\n",
        "\n",
        "* WT2   \n",
        "\n",
        "   ![WT2](http://imgnews.naver.net/image/5366/2019/05/04/2019050309193902535b5d048c6f32181566211_20190504080223240.jpg)   \n",
        "   \n",
        "* 참고 자료   \n",
        "\n",
        "    [네이버 블로그](https://post.naver.com/viewer/postView.nhn?volumeNo=26062708&memberNo=16226184)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUUXEQDy_RsB",
        "colab_type": "text"
      },
      "source": [
        "## 2. 음성 분야   \n",
        "\n",
        "\n",
        "* 우리가 인공지능 기반 음성인식 제품에 말을 하면, “음성 입력 및 인식 → 자연어 처리 → 인식 결과”의 단계를 거친다.   \n",
        "첫 번째 과정에서는 음성 입력 과정을 거쳐 사람의 음성을 컴퓨터가 이해할 수 있도록 텍스트화한다. 이 기술을 STT(Speech To Text)라고 하는데요. 어린아이가 받아쓰기를 하듯이 사람의 음성을 텍스트로 옮기는 것이다. 주변 소음을 제외한 말소리를 파악하고 이어서 각 발음과 단어를 인식한 후 핵심어와 연결 단어를 인식해 입력해야 하므로 생각보다 간단하고 쉽지만은 않다.   \n",
        " 두 번째는 자연어 처리(Natural Language Processing, NLP) 과정이다. 자연어란 사람이 의사소통을 위해 사용하는 언어다. 자연어 처리란 컴퓨터가 자연어를 분석하여 이해하고 처리하는 기술이다. \n",
        "이 과정에서는 자연어에 대한 형태소 분석, 구문 해석, 의미 분석, 화용 분석 등을 통해 컴퓨터가 문장에 담긴 의도를 파악하게 한다. 이 자연어 처리는 인공지능의 주요 분야이다. 인공지능 기계가 사람의 언어를 얼마나 잘 파악하였는지를 알 수 있는 과정이다.   \n",
        " 앞선 과정을 거쳐 마지막으로 기계는 인식 결과를 내놓는다. 인식된 요청에 따라 가장 최적의 결과를 찾아내고, TTS(Text to Speech) 기술을 통해 사람의 말소리처럼 응답하는 것이다. 친구에게 메시지를 보내라고 말했다면 전달한 내용으로 메시지를 전송하고, 날씨를 물어봤다면 인터넷에서 위치 기반의 날씨를 검색해 대답해준다.   \n",
        "    \n",
        "\n",
        "* 음성 분야에 인공지능이 적용된 사례로는 AI 스피커 'NUGU'가 있다. NUGU는 음성인식 기반의 인공지능 서비스이다. 기능으로는 장르에 맞는 음악을 틀어달라고 부탁하면 그에 맞는 음악을 틀어주고, TV나 알람, 미리 등록된 일정까지 알려달라고 하면 음성으로 알려주는 기능이 있다. 이 밖에 통화기능, 뉴스 정보, 날씨 등의 기능도 알려달라고하면 음성을 인식하여 알려준다.   \n",
        "   \n",
        "\n",
        "* AI 스피커 NUGU   \n",
        "\n",
        " ![NUGU](https://ww.namu.la/s/2755a4603625ad0ed76e296f0db4c3a45f04082501e2248894707a9cbe268325bb10d6ede299c3aafa4544e9f203fa9f2d89e6cf9015c79e77193efcc5cc25fad3a02975f41881a1050653930606357d690b9817058ae8fb99d176a7d0e97846)   \n",
        "   \n",
        "* 참고 자료    \n",
        "\n",
        " [음성인식 인공지능 포스트](https://www.mobiinside.co.kr/2020/04/28/flitto-ai/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsWGpZ6yF3S_",
        "colab_type": "text"
      },
      "source": [
        "## 3. 이미지 분야   \n",
        "* 이미지 분야에 적용된 인공지능 사례로는 이큐포올 사의 'SUZI' 서비스가 있다. 'SUZI'라고 명명된 수화 자동 통역기 프로젝트는 농아와 사회 사이의 벽이없는 세상을 만들기 위한 장기적인 목표이다. 이 서비스는 TV 셋톱박스나 웹 비디오에서 아바타 기반의 손 번역 앱에서 Live 방송과 VOD 콘텐츠의 음성 신호 또는 자막을 활용하여 선택적인 번역 서비스를 제공하고, 웹 사이트에서 아바타 기반의 번역 서비스를 제공하여 청각장애인의 웹에서의 접근성을 향상시킨다. 이 밖에 키오스크 장비에 아바타 기반의 수어 번역 응용 프로그램을 탑재하여 청각장애인의 접근성과 참여를 높이는 서비스, 자동차 장비에 수어를 인식하고 아바타 애니메이션을 통해 정보를 전달할 수 있도록 솔루션을 개발하고 있다.   \n",
        "   \n",
        "   \n",
        "* 이큐포올 사의 'SUZI'   \n",
        "![suzi](http://www.aitimes.kr/news/photo/202005/16445_17848_3041.jpg)   \n",
        "   \n",
        "* 참고 자료    \n",
        "\n",
        " [이큐포올](https://www.eq4all.co.kr/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4P6rHB3KnWS",
        "colab_type": "text"
      },
      "source": [
        "## 4. 자율주행 분야    \n",
        "* 자율주행 모빌리티 센서 기업 인포웍스의 자율주행차량용 센서인 FMCW(Frequency Modulated Continuous Wave) 라이다 기술이 '2020 인공지능중심 산업융합 집적단지 조성사업 산업융합형 AI 연구개발 사업'의 '자동차 AI 융합 연구개발 사업'부분에 최종 선정되었다.   \n",
        "과거에 널리 쓰이던 라이다 기술은 레이저가 되돌아오는 속도를 측정하는 방식이다. 하지만 이 기술은 낮은 조도, 눈, 비, 안개, 온도, 태양광 등 열악한 환경에 취약하다는 문제점과 향후 라이다가 장착된 자율주행차량이 늘어나게 되었을 때 라이다 간 간섭으로 물체 인식에 오류가 발생할 수 있다는 문제점에 주파수 변조법(FWCW) 라이다 센서 기술은 이를 동시에 해결할 수 있다. 인포웍스의 FMCW 라이다 기술과 다중 센서 융합 기술을 접목하여 자동차 산업의 경쟁력을 높일 것으로 기대하며, 국내외 다양한 업체 및 기관과의 협업을 통해 해당 기술을 여러 사업분야에 적용할 수 있을 것으로 본다.   \n",
        "   \n",
        "\n",
        "* 인포웍스 사의 'FWCW' 라이다 기술   \n",
        "![FWCW](http://www.aitimes.kr/news/photo/202005/16406_17798_38.png)   \n",
        "\n",
        "* 참고자료   \n",
        "   \n",
        " [인공지능 신문](http://www.aitimes.kr/news/articleView.html?idxno=16406)\n"
      ]
    }
  ]
}